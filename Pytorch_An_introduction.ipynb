{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM3km3EyoV4W49mYOn/t/L+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/franciskyalo/Pytorch-Learning/blob/main/Pytorch_An_introduction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "# An Introduction to Pytorch\n"
      ],
      "metadata": {
        "id": "OoxR__sO_eez"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "PyTorch is an open-source machine learning framework primarily used for deep learning applications. It has gained popularity for its flexibility, dynamic computation graph, and user-friendly interface. Here's a brief history of PyTorch:\n",
        "\n",
        "### Origins\n",
        "- **2016**: PyTorch was developed by the **Artificial Intelligence Research Group (FAIR)** at Facebook. It was built on the foundation of **Torch**, a machine learning library written in Lua, which had been widely used in academic research but lacked adoption in the broader industry.\n",
        "\n",
        "- **Key Contributors**:\n",
        "  - **Adam Paszke** and other researchers from FAIR played significant roles in its development.\n",
        "  - It incorporated many modern design principles to make it more accessible and flexible compared to Torch.\n",
        "\n",
        "### Early Features\n",
        "- PyTorch introduced a **dynamic computation graph**, allowing developers to modify the model architecture during runtime. This was a significant departure from static graph frameworks like TensorFlow 1.x, making it especially appealing to researchers.\n",
        "\n",
        "- PyTorch was designed with a focus on Python, making it intuitive and easy to integrate with Pythonâ€™s rich ecosystem of libraries.\n",
        "\n",
        "### Adoption and Growth\n",
        "- By **2017**, PyTorch began gaining traction among researchers, thanks to its ease of use, dynamic nature, and robust community support.\n",
        "\n",
        "- It became a favorite in academic research, where experimentation and model iteration are frequent.\n",
        "\n",
        "### Key Milestones\n",
        "1. **2018**:\n",
        "   - **PyTorch 1.0**: Facebook merged PyTorch with another of its frameworks, **Caffe2**, to combine research flexibility with production capabilities.\n",
        "   - This version included improved support for deploying models in production environments.\n",
        "\n",
        "2. **2019**:\n",
        "   - PyTorch introduced **TorchScript**, enabling the export of models to a statically defined computational graph for optimized deployment.\n",
        "   - It became the framework of choice for many prestigious conferences and competitions in the deep learning community.\n",
        "\n",
        "3. **2020**:\n",
        "   - PyTorch released support for **distributed training** and **hardware accelerators** like TPUs.\n",
        "   - It was increasingly adopted by industry leaders like Tesla, Microsoft, and Uber for real-world applications.\n",
        "\n",
        "4. **2021-2023**:\n",
        "   - PyTorch grew its ecosystem with libraries like **TorchVision** (for computer vision), **TorchText** (for natural language processing), and **TorchAudio** (for audio processing).\n",
        "   - It introduced advanced features like **torch.compile** (dynamic compilation for performance optimization).\n",
        "\n",
        "5. **2022**:\n",
        "   - Facebook rebranded as Meta, reaffirming its commitment to PyTorch by transferring the framework to the **PyTorch Foundation**, part of the Linux Foundation. This ensured that PyTorch would remain community-driven and open-source.\n",
        "\n",
        "6. **2023 and Beyond**:\n",
        "   - PyTorch continues to innovate with improvements in scalability, support for large models (e.g., Transformers), and integration with tools for reinforcement learning, generative AI, and more.\n",
        "\n",
        "### Impact\n",
        "- PyTorch has played a crucial role in democratizing deep learning by providing an accessible yet powerful platform for both researchers and practitioners.\n",
        "- It remains one of the most widely used frameworks in academia and industry, competing closely with TensorFlow.\n",
        "\n",
        "PyTorch's emphasis on flexibility, coupled with its growing ecosystem and robust community support, has solidified its position as a cornerstone of modern AI and deep learning."
      ],
      "metadata": {
        "id": "irw06-O6BFG7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Introduction to Tensors"
      ],
      "metadata": {
        "id": "VE_qCy7LB9j1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A **tensor** is a multi-dimensional array or matrix used to represent data in deep learning and other numerical computations. Tensors generalize vectors and matrices to higher dimensions, making them highly versatile for handling complex datasets and computations in neural networks.\n",
        "\n",
        "### Key Characteristics of Tensors\n",
        "1. **Dimensionality**:\n",
        "   - A **scalar** is a tensor with zero dimensions (e.g., \\(5\\)).\n",
        "   - A **vector** is a 1-dimensional tensor (e.g., \\([1, 2, 3]\\)).\n",
        "   - A **matrix** is a 2-dimensional tensor (e.g., \\(\\begin{bmatrix} 1 & 2 \\\\ 3 & 4 \\end{bmatrix}\\)).\n",
        "   - Higher-dimensional tensors are often referred to as n-dimensional tensors.\n",
        "\n",
        "2. **Shape**:\n",
        "   The shape of a tensor indicates the number of elements along each dimension. For example:\n",
        "   - A 1D tensor with 3 elements: `(3,)`.\n",
        "   - A 2D tensor with 2 rows and 3 columns: `(2, 3)`.\n",
        "   - A 3D tensor, e.g., representing a batch of images: `(batch_size, height, width)`.\n",
        "\n",
        "3. **Data Types**:\n",
        "   Tensors can hold various data types like integers, floating-point numbers, or even Boolean values. The data type must be specified when defining the tensor.\n",
        "\n",
        "4. **Operations**:\n",
        "   Tensors are the building blocks of deep learning models. They support various operations such as addition, multiplication, reshaping, slicing, and more. These operations are highly optimized for GPUs and other accelerators.\n",
        "\n",
        "### Importance in Deep Learning\n",
        "- **Data Representation**:\n",
        "  Tensors are used to represent all forms of input data (e.g., images, text, audio).\n",
        "  - Images: Stored as 3D tensors (`[height, width, channels]`).\n",
        "  - Text: Represented as sequences or embeddings in tensors.\n",
        "  - Video: Stored as 4D tensors (`[frames, height, width, channels]`).\n",
        "\n",
        "- **Model Parameters**:\n",
        "  The weights and biases in neural networks are stored as tensors.\n",
        "\n",
        "- **Parallel Computation**:\n",
        "  Frameworks like PyTorch and TensorFlow use tensors to perform computations efficiently on GPUs and TPUs.\n",
        "\n",
        "### Example in PyTorch\n",
        "```python\n",
        "import torch\n",
        "\n",
        "# Scalar\n",
        "scalar = torch.tensor(5)\n",
        "print(scalar.shape)  # Output: torch.Size([])\n",
        "\n",
        "# Vector\n",
        "vector = torch.tensor([1, 2, 3])\n",
        "print(vector.shape)  # Output: torch.Size([3])\n",
        "\n",
        "# Matrix\n",
        "matrix = torch.tensor([[1, 2], [3, 4]])\n",
        "print(matrix.shape)  # Output: torch.Size([2, 2])\n",
        "\n",
        "# 3D Tensor\n",
        "tensor_3d = torch.randn(3, 3, 3)  # Random 3x3x3 tensor\n",
        "print(tensor_3d.shape)  # Output: torch.Size([3, 3, 3])\n",
        "```\n",
        "\n",
        "Tensors are foundational in deep learning, enabling the storage and manipulation of data and parameters in neural networks."
      ],
      "metadata": {
        "id": "mdCmujNG__gC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Writing Pytorch Code"
      ],
      "metadata": {
        "id": "h-Mh25b9H2do"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Introduction to Pytorch Tensors"
      ],
      "metadata": {
        "id": "ElpT94TSJQ7g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In PyTorch, tensors are versatile data structures that support various data types and functionalities. While all PyTorch tensors are fundamentally the same type, their behavior can differ based on their **data type**, **device**, **dimensionality**, or **special purpose**. Here are the main classifications:\n",
        "\n",
        "---\n",
        "\n",
        "### **1. Based on Dimensionality**\n",
        "- **Scalar Tensor**: A zero-dimensional tensor, representing a single number.\n",
        "  ```python\n",
        "  scalar = torch.tensor(5)\n",
        "  print(scalar.dim())  # Output: 0\n",
        "  ```\n",
        "\n",
        "- **Vector Tensor**: A one-dimensional tensor, representing a list of numbers.\n",
        "  ```python\n",
        "  vector = torch.tensor([1, 2, 3])\n",
        "  print(vector.dim())  # Output: 1\n",
        "  ```\n",
        "\n",
        "- **Matrix Tensor**: A two-dimensional tensor, representing a grid of numbers.\n",
        "  ```python\n",
        "  matrix = torch.tensor([[1, 2], [3, 4]])\n",
        "  print(matrix.dim())  # Output: 2\n",
        "  ```\n",
        "\n",
        "- **Higher-Dimensional Tensor**: Tensors with three or more dimensions, used for more complex data.\n",
        "  ```python\n",
        "  tensor_3d = torch.rand(3, 4, 5)  # 3D tensor\n",
        "  tensor_4d = torch.rand(2, 3, 4, 5)  # 4D tensor\n",
        "  ```\n",
        "\n",
        "---\n",
        "\n",
        "### **2. Based on Data Type**\n",
        "PyTorch tensors can hold different types of data. Common types include:\n",
        "- **Float Tensors** (default): `torch.float32`\n",
        "  ```python\n",
        "  tensor = torch.tensor([1.0, 2.0], dtype=torch.float32)\n",
        "  ```\n",
        "\n",
        "- **Double Tensors**: `torch.float64`\n",
        "  ```python\n",
        "  tensor = torch.tensor([1.0, 2.0], dtype=torch.float64)\n",
        "  ```\n",
        "\n",
        "- **Integer Tensors**:\n",
        "  - `torch.int32` or `torch.int64`\n",
        "  ```python\n",
        "  tensor = torch.tensor([1, 2], dtype=torch.int32)\n",
        "  ```\n",
        "\n",
        "- **Boolean Tensors**: `torch.bool`\n",
        "  ```python\n",
        "  tensor = torch.tensor([True, False], dtype=torch.bool)\n",
        "  ```\n",
        "\n",
        "- **Complex Tensors**: `torch.complex64` or `torch.complex128`\n",
        "  ```python\n",
        "  tensor = torch.tensor([1+2j, 3+4j], dtype=torch.complex64)\n",
        "  ```\n",
        "\n",
        "---\n",
        "\n",
        "### **3. Based on Device**\n",
        "Tensors can reside on different devices:\n",
        "- **CPU Tensors**: The default device.\n",
        "  ```python\n",
        "  tensor = torch.tensor([1, 2, 3])\n",
        "  ```\n",
        "\n",
        "- **GPU Tensors**: Leveraging CUDA for faster computation.\n",
        "  ```python\n",
        "  tensor = torch.tensor([1, 2, 3], device='cuda')\n",
        "  ```\n",
        "\n",
        "- **TPU Tensors**: For advanced hardware accelerators (requires libraries like PyTorch XLA).\n",
        "\n",
        "---\n",
        "\n",
        "### **4. Based on Gradient Computation**\n",
        "- **Regular Tensor**: No gradient tracking.\n",
        "  ```python\n",
        "  tensor = torch.tensor([1.0, 2.0])\n",
        "  ```\n",
        "\n",
        "- **Tensor with Gradients**: Used for automatic differentiation in models.\n",
        "  ```python\n",
        "  tensor = torch.tensor([1.0, 2.0], requires_grad=True)\n",
        "  ```\n",
        "\n",
        "---\n",
        "\n",
        "### **5. Special Tensors**\n",
        "- **Sparse Tensors**: Efficient storage for tensors with mostly zero values.\n",
        "  ```python\n",
        "  indices = torch.tensor([[0, 1], [1, 2]])\n",
        "  values = torch.tensor([3, 4])\n",
        "  sparse_tensor = torch.sparse_coo_tensor(indices, values, [2, 3])\n",
        "  ```\n",
        "\n",
        "- **Quantized Tensors**: Reduced precision for memory-efficient inference.\n",
        "  ```python\n",
        "  tensor = torch.quantize_per_tensor(torch.tensor([1.0, 2.0]), scale=0.1, zero_point=0, dtype=torch.qint8)\n",
        "  ```\n",
        "\n",
        "- **Complex Tensors**: For working with complex numbers.\n",
        "  ```python\n",
        "  tensor = torch.tensor([1+2j, 3+4j])\n",
        "  ```\n",
        "\n",
        "- **Custom Tensors**: You can define custom tensors by extending the PyTorch library.\n",
        "\n",
        "---\n",
        "\n",
        "### Summary Table\n",
        "\n",
        "| **Classification** | **Example**                                                                 |\n",
        "|---------------------|-----------------------------------------------------------------------------|\n",
        "| Dimensionality      | Scalar, Vector, Matrix, Higher-dimensional tensors                         |\n",
        "| Data Type           | Float, Integer, Boolean, Complex                                           |\n",
        "| Device              | CPU, GPU, TPU                                                             |\n",
        "| Gradients           | Regular tensors, Tensors with `requires_grad=True`                        |\n",
        "| Special Tensors     | Sparse tensors, Quantized tensors, Complex tensors                        |\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "m1_1KShUJXRF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "UgEEPd6BaN4B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "981a0bdb-737e-4405-9be1-af6da7f5b265"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.5.1+cu121\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "print(torch.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = torch.tensor(8)\n",
        "scaler"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y7AxqrSO-l8U",
        "outputId": "dc55603a-bc48-43db-d185-9bc294dd64b1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(8)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scaler.ndim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KLbAGYyhKNnS",
        "outputId": "061612d0-aa78-4d23-e15f-bb6ea78620eb"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scaler.item()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YievDnY7KUEh",
        "outputId": "7b2930aa-286c-4593-c550-5ce60f238b62"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vector=torch.tensor([1,2,7,8])\n",
        "\n",
        "vector"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tR0n8xYPKiJB",
        "outputId": "1884b65e-9e77-4523-add4-ffacf54632fc"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 7, 8])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vector.dim()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E6krnNN8Knxl",
        "outputId": "cd1db059-4680-4249-9502-b95a2deb0201"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vector.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZwYCQwWqKz5K",
        "outputId": "4d814e31-b17c-4c67-a729-5dd4c6be17dc"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "matrix_tensor = torch.tensor([[1,2,3],[4,5,6]])\n",
        "matrix_tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cZqxuYnPK5XG",
        "outputId": "c4c324c6-836a-4fb8-bbd1-70674a1d5afb"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2, 3],\n",
              "        [4, 5, 6]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "matrix_tensor.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zj_GeU1SLDuq",
        "outputId": "82c16129-3eef-40b1-a578-64219d7f43b4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "matrix_tensor[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TVDRdoVqLMdn",
        "outputId": "b97e76bc-907a-4ef7-83d7-7bd4b5ce4790"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# random tensors\n",
        "\n",
        "random_tensor = torch.rand(3,4)\n",
        "random_tensor"
      ],
      "metadata": {
        "id": "TVrfqDA0Lh2M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "463fac05-dd9a-43c2-a20d-8030093e31e4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.9496, 0.0213, 0.7218, 0.6857],\n",
              "        [0.8017, 0.6428, 0.0728, 0.4381],\n",
              "        [0.0829, 0.6141, 0.6514, 0.8354]])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "normal_random_tensor = torch.randn(3,4)\n",
        "normal_random_tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pUPYhxoDR8o8",
        "outputId": "a424cc82-6610-47f9-fa77-e01e25a5b3ae"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.0143, -2.2737,  0.3219,  0.4916],\n",
              "        [ 0.1752, -0.8686, -1.7628,  0.3200],\n",
              "        [-0.5571, -0.4384,  1.2328, -0.7139]])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random_image_size_tensor = torch.rand(size=(224,224,3))\n",
        "random_image_size_tensor.shape, random_image_size_tensor.ndim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qtWEFjHWSP_S",
        "outputId": "eb841f99-bfee-409f-a352-bc61bbd9c142"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([224, 224, 3]), 3)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#zero tensors\n",
        "zero_tensor=torch.zeros(size=(3,4))\n",
        "zero_tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fxBvf-5CS3LP",
        "outputId": "c0b2d8f0-90c6-47a3-e8d7-60c88bf9cede"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ones tensors\n",
        "\n",
        "ones_tensors=torch.ones(size=(3,4))\n",
        "ones_tensors"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SBCIwHeUTF8S",
        "outputId": "838eb0a6-4ffb-4874-b1af-2c9bf4283ce2"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# checking the data type\n",
        "\n",
        "ones_tensors.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4kYdaZ4TN5X",
        "outputId": "386119d5-7449-48d1-b733-c867ad71cb9c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a range of tensors\n",
        "\n",
        "range_torch = torch.arange(0,10)\n",
        "range_torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iRTmD1duhuee",
        "outputId": "6a39d6f4-17aa-43d9-ba55-af7127f906fc"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# including step\n",
        "\n",
        "step_range_torch = torch.arange(start=0,end=1000,step=77)\n",
        "step_range_torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "luTeFEbPiDtq",
        "outputId": "18790079-d100-4723-a7f4-6bdc6f41af45"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([  0,  77, 154, 231, 308, 385, 462, 539, 616, 693, 770, 847, 924])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# creating tensors-like\n",
        "\n",
        "tensors_like="
      ],
      "metadata": {
        "id": "ovIAqgoJiUyA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}